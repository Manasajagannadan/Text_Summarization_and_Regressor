{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Work2_came.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbSt2WDW0mqY",
        "colab_type": "text"
      },
      "source": [
        "**Working on Claims severity :** Task is to create a better model and to find the predict the value for the 'loss' column. Variables prefaced with 'cat' are categorical, while those prefaced with 'cont' are continuous.Means must *predict the loss value for the ids in this file.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw-uyCjV5ob9",
        "colab_type": "text"
      },
      "source": [
        "# Here I am working with Tensorflow application **Regression model** named as DNNRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibjKxo-OsV9D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6676f28b-95e2-444f-f308-073eb48c9ea7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLiCAAcx1bOQ",
        "colab_type": "text"
      },
      "source": [
        "For download the dataset click on the below link :\n",
        "[link text](https://www.kaggle.com/c/allstate-claims-severity/data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYLXHLG_15Wy",
        "colab_type": "text"
      },
      "source": [
        "(By Jagannadan Manasa), Now i am trying to solve these Claims severity using a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_AtjmyZ2anh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAY-FUlh2aqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_o = pd.read_csv('/content/drive/My Drive/train.csv')\n",
        "test_o = pd.read_csv('/content/drive/My Drive/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiyijOKo4D0T",
        "colab_type": "code",
        "outputId": "ed62c951-b3eb-46cd-c328-0ea3721b7941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train_df = train_o.head(1000)\n",
        "evaluate_df = train_o.tail(500)\n",
        "\n",
        "test_df = test_o.head(1000)\n",
        "\n",
        "MODEL_DIR = \"tf_model_full\"\n",
        "\n",
        "print(\"train_df.shape = \", train_df.shape)\n",
        "print(\"evaluate_df.shape = \", evaluate_df.shape)\n",
        "print(\"test_df.shape = \", test_df.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_df.shape =  (1000, 132)\n",
            "evaluate_df.shape =  (500, 132)\n",
            "test_df.shape =  (1000, 131)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvxT_srCr380",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = train_df.columns\n",
        "categorical_features = [feature for feature in features if 'cat' in feature]\n",
        "continuous_features = [feature for feature in features if 'cont' in feature]\n",
        "LABEL_COLUMN = 'loss'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGYjIc5J7wFq",
        "colab_type": "text"
      },
      "source": [
        "# Convert the data in **Tensors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmjpGgUcr4l3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_fn(df, training = True):\n",
        "    continuous_cols = {k: tf.constant(df[k].values)\n",
        "                       for k in continuous_features}\n",
        "    categorical_cols = {k: tf.SparseTensor(\n",
        "        indices=[[i, 0] for i in range(df[k].size)],\n",
        "        values=df[k].values,\n",
        "        dense_shape=[df[k].size, 1])\n",
        "        for k in categorical_features}\n",
        "    feature_cols = dict(list(continuous_cols.items()) +\n",
        "                        list(categorical_cols.items()))\n",
        "\n",
        "    if training:\n",
        "        label = tf.constant(df[LABEL_COLUMN].values)\n",
        "        return feature_cols, label    \n",
        "    return feature_cols\n",
        "\n",
        "def train_input_fn():\n",
        "    return input_fn(train_df)\n",
        "\n",
        "def eval_input_fn():\n",
        "    return input_fn(evaluate_df)\n",
        "\n",
        "def test_input_fn():\n",
        "    return input_fn(test_df, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmWgSIZ_r4q9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "engineered_features = []\n",
        "\n",
        "for continuous_feature in continuous_features:\n",
        "    engineered_features.append(\n",
        "        tf.contrib.layers.real_valued_column(continuous_feature))\n",
        "\n",
        "\n",
        "for categorical_feature in categorical_features:\n",
        "    sparse_column = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
        "        categorical_feature, hash_bucket_size=1000)\n",
        "\n",
        "    engineered_features.append(tf.contrib.layers.embedding_column(sparse_id_column=sparse_column, dimension=16,\n",
        "                                                                  combiner=\"sum\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4Vp0SM8r4pJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regressor = tf.contrib.learn.DNNRegressor(\n",
        "    feature_columns=engineered_features, hidden_units=[10, 10], model_dir=MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l052od072Z-",
        "colab_type": "text"
      },
      "source": [
        "# Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RL72KVNr35o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrap = regressor.fit(input_fn = train_input_fn, steps=500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG5RoaLbsDoL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3e3a8b82-1324-413e-fd71-a25acceeb48c"
      },
      "source": [
        "print('Evaluating ...')\n",
        "results = regressor.evaluate(input_fn=eval_input_fn, steps=1)\n",
        "for key in sorted(results):\n",
        "    print(\"%s: %s\" % (key, results[key]))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating ...\n",
            "global_step: 1000\n",
            "loss: 9180887.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHdT41_HsDmt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "485fafdf-e00c-4747-9337-13cac84b0524"
      },
      "source": [
        "predicted_output = regressor.predict(input_fn=test_input_fn)\n",
        "set2_list = list(predicted_output )\n",
        "print(list(set2_list[:10]))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1368.6537, 2674.0889, 24399.498, 8121.3813, 885.21735, 4133.063, 1269.4844, 2564.876, 2470.7866, 2663.6309]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXuG1LITyTzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ID = df_test_ori['id']\n",
        "df_test_ori.drop('id',axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv-UN3JL78sw",
        "colab_type": "text"
      },
      "source": [
        "# Save the results submission1.csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5ykndbdsDf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "with open(\"submission1.csv\", \"w\") as subfile:\n",
        "    subfile.write(\"id,loss\\n\")\n",
        "    for i, pred in enumerate(list(set2_list)):\n",
        "        subfile.write(\"%s,%s\\n\"%(ID[i],pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsz_KLnpsDbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5EXI7yBsDX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpcqI4qisDU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3oSNvsIsDS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}